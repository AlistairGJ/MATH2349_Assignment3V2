{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf400
{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fnil\fcharset0 TrebuchetMS;\f2\froman\fcharset0 Times-Roman;
\f3\fswiss\fcharset0 ArialMT;\f4\fnil\fcharset0 Monaco;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red255\green255\blue255;\red33\green33\blue33;
\red60\green60\blue59;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;\cssrgb\c100000\c100000\c100000;\cssrgb\c17255\c17255\c17255;
\cssrgb\c30196\c30196\c29804;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}.}{\leveltext\leveltemplateid1\'02\'00.;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid1}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}}
\paperw11900\paperh16840\margl1440\margr1440\vieww18240\viewh25700\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs36 \cf0 \
\
The Gun Violence Dataset contains data from January 2013 till March 2018, inclusive. The US Census data, however, was generated from a 2015 census. The GVD dataset will thus be filtered to only contain data from 2015. \
\
We wanted to explore the relationship between gun violence and political influence in the geographic area. In order to do this, we will first extract the relevant geographical and political information for the year 2015 from `gvd2015`.\
\

\b Chunk - \{r Checking Column Names of gvd2015_GeoPol, message=FALSE, warning=FALSE, paged.print=TRUE\} 
\b0 These data will now be checked for NaN values.\
\
We can see that while state and city_or_county contain no na values, \
\
Hypothesis - All 51 states have uniques names. Unknown number of city_or_county values are not all unique. We may use the concatenated state + city_or_county values to find the congressional district + state house district + state senate district \'97> in the context of this activity this will be regarded as an imputation.\
\
OR conditional fill \
\
OR go state-by-state\
\
OR go line-by-line\'85\
\
** Count unique values for both columns\
** Concatenate then count again\
**\
\
\
\pard\pardeftab720\sl400\sa240\partightenfactor0

\f1\b\fs34\fsmilli17333 \cf2 \cb3 \expnd0\expndtw0\kerning0
Report Section Details 
\f2\b0\fs24 \cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl340\sa293\partightenfactor0
\ls1\ilvl0
\f3\b\fs29\fsmilli14667 \cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	1.	}\expnd0\expndtw0\kerning0
Report title and group/individual details [Plain text]
\f2  
\f3 : You can add the title of your report and student(s) details by updating the \'93title\'94 and \'93author\'94 entries at the top of the R Markdown Template. \cb1 \uc0\u8232 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	2.	}\expnd0\expndtw0\kerning0
Required packages [R code]: Provide the packages required to reproduce the report. Make sure you fulfilled the minimum requirement #10. \cb1 \uc0\u8232 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	3.	}\expnd0\expndtw0\kerning0
Executive Summary [Plain text]
\f2  
\f3 : In your own words, provide a brief summary of the preprocessing. Explain the steps that you have taken to preprocess your data. Write this section last after you have performed all data preprocessing. (Word count Max: 300 words) \cb1 \uc0\u8232 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	4.	}\expnd0\expndtw0\kerning0
Data [Plain text & R code & Output]: A clear description of data sets, their sources, and variable descriptions should be provided. In this section, you must also provide the R codes with outputs (head of data sets) that you used to import/read/scrape the data set. You need to fulfil the minimum requirement #1 and merge at least two data sets to create the one you are going to work on. In addition to the R codes and outputs, you need to explain the steps that you have taken. \cb1 \uc0\u8232 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	5.	}\expnd0\expndtw0\kerning0
Understand [Plain text & R code & Output]: Summarise the types of variables and data structures, check the attributes in the data. In addition to the R codes and outputs, explain briefly the steps that you have taken. In this section, show that you have fulfilled minimum requirements 2-4. \cb1 \uc0\u8232 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	6.	}\expnd0\expndtw0\kerning0
Tidy & Manipulate Data I [Plain text & R code & Output]: Check if the data conforms the tidy data principles. If your data is not in a tidy format, reshape your data into a tidy format (minimum requirement #5). In addition to the R codes and outputs, explain everything that you do in this step. \cb1 \uc0\u8232 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	7.	}\expnd0\expndtw0\kerning0
Tidy & Manipulate Data II [Plain text & R code & Output]: Create/mutate at least one variable from the existing variables (minimum requirement #6). In addition to the R codes and outputs, explain everything that you do in this step. \cb1 \uc0\u8232 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	8.	}\expnd0\expndtw0\kerning0
Scan I [Plain text & R code & Output]: Scan the data for missing values, inconsistencies and obvious errors. In this step, you should fulfil the minimum requirement #7. In addition to the R codes and outputs, explain how you dealt with these values. \cb1 \uc0\u8232 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	9.	}\expnd0\expndtw0\kerning0
Scan II [Plain text & R code & Output]: Scan the numeric data for outliers. In this step, you should fulfil the minimum requirement #8. In addition to the R codes and outputs, explain how you dealt with these values. \cb1 \uc0\u8232 
\f2\b0\fs24 \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\f3\b\fs29\fsmilli14667 \cf2 \cb3 10. Transform [Plain text & R code & Output]: 
\b0 Apply an appropriate transformation for at least one of the variables. In addition to the R codes and outputs, explain everything that you do in this step. In this step, you should fulfil the minimum requirement #9. 
\f2\fs24 \cb1 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs36 \cf0 \kerning1\expnd0\expndtw0 \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\f3\fs29\fsmilli14667 \cf2 \cb3 \expnd0\expndtw0\kerning0
This assignment assesses the following Course Learning Objectives: 
\f2\fs24 \cb1 \

\f3\fs29\fsmilli14667 \cb3 1. Critically reflect upon different data sources, types, formats and structures.\cb1 \uc0\u8232 \cb3 2. Apply data integration techniques to import and combine different sources of data.\cb1 \uc0\u8232 \cb3 3. \cf4 Apply different data manipulation techniques to recode, filter, select, split, aggregate, and reshape the data into a format suitable for statistical analysis. 
\f2\fs24 \cf2 \cb1 \

\f3\fs29\fsmilli14667 \cb3 4. \cf4 Justify data by detecting and handling missing values, outliers, inconsistencies and errors.\cb1 \uc0\u8232 \cf2 \cb3 5. \cf4 Demonstrate practical experience by having been exposed to real data problems.\cb1 \uc0\u8232 \cf2 \cb3 6. \cf4 Effectively use leading open source software for reproducible, automated data preprocessing. \
\
\
\pard\pardeftab720\sl420\partightenfactor0

\f4 \cf5 \cb1  [1] "CensusId"        "State"           "County"          "TotalPop"        "Men"             "Women"          \
 [7] "Hispanic"        "White"           "Black"           "Native"          "Asian"           "Pacific"        \
[13] "Citizen"         "Income"          "IncomeErr"       "IncomePerCap"    "IncomePerCapErr" "Poverty"        \
[19] "ChildPoverty"    "Professional"    "Service"         "Office"          "Construction"    "Production"     \
[25] "Drive"           "Carpool"         "Transit"         "Walk"            "OtherTransp"     "WorkAtHome"     \
[31] "MeanCommute"     "Employed"        "PrivateWork"     "PublicWork"      "SelfEmployed"    "FamilyWork"     \
[37] "Unemployment"   \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\f3 \cf4 \cb3 \
\pard\pardeftab720\sl420\partightenfactor0

\f4 \cf5 \cb1 [1] "incident_id"                 "date"                        "state"                       "city_or_county"             \
 [5] "address"                     "n_killed"                    "n_injured"                   "incident_url"               \
 [9] "source_url"                  "incident_url_fields_missing" "congressional_district"      "gun_stolen"                 \
[13] "gun_type"                    "incident_characteristics"    "latitude"                    "location_description"       \
[17] "longitude"                   "n_guns_involved"             "notes"                       "participant_age"            \
[21] "participant_age_group"       "participant_gender"          "participant_name"            "participant_relationship"   \
[25] "participant_status"          "participant_type"            "sources"                     "state_house_district"       \
[29] "state_senate_district"   \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\f3 \cf4 \cb3 \
Developing a methodology to join these data sets proved to be problematic. The subsequent ordering of the report is based on the cleaning of acs2015_keep_cali and using this as the platform for which the other data set was to be cleaned.\
\
\
Executive Summary\
The libraries `readr`, `diplyr`, `stringr`, `knitr`, `tidyr`, `lubridate`, `kableExtra`, `outliers` and `ggplot2` were imported into the RStudio interactive development environment. The .csv files \'93gun-violence-data\'94 (Gun Violence Data, kaggle.com) and \'93American Census Data 2015\'94 (US Census Demographic and Economic Data, kaggle.com) were imported as `gvd` and `acs2015`, respectively. These data were then checked for tidiness (`gvd` untidy, `acs2015` tidy), dimensions (`gvd` 239677 obs. of 29 var., `acs2015` 3220 obs. of 37 var.), NA count attribute classes (see summary tables, below). \
The `gvd` dataset failed to conform to the \'93tidy data\'94 principals. Most notably, every instance of the attributes prefixed \'93participant_\'94 contained multiple values, delimited by a combination of [:digit:], :: and/or ||. In order to be computationally efficient, it was decided to first subset `gvd` before cleaning the aforementioned \'93participant_\'94 attributes. \
As the `acs2015` dataset contained values from only the 2015 American (US) Census, the first subset involved filtering values of the year 2015 from the `gvd` dataset. Using the `as.logical()` and `year()` functions, a boolean vector was created and applied to `gvd` to create the dataset `gvd2015`. This methodology enabled us to retain the native date format YYYY-MM-DD. The `gvd2015` was then filtered for values which satisfied the condition `state == \'93California\'94`, giving `gvd2015_keep_cali`. It was determined that the `incident_url` column of `gvd2015_keep_cali` could be dropped, as the URL prefix in every case matched the unique incident ID.\
A custom function was written and employed to scour through the `participant_age` column of `gvd2015`. This resulted in capturing age counts of incident participants by binning them into approximately 5-years bin intervals. The `participant, _gender, _status, _type` columns were then also all stripped of string prefix values and binned. The resultant `killed_count` and `injured_count` matched perfectly the original `n_killed` and `n_injured` attributes, indicating an extremely precise processing methodology. \
\
__________\
\
The required libraries were imported into the RStudio interactive development environment, followed by the .csv files \'93gun-violence-data\'94 and \'93American Census Data 2015\'94 as `gvd` and `acs2015`, respectively. These data were then checked for tidiness (`gvd` untidy, `acs2015` tidy), dimensions (`gvd` 239677 obs. of 29 var., `acs2015` 3220 obs. of 37 var.), NA count and attribute classes (see summary tables, below). \
The `gvd` dataset failed to conform to the \'93tidy data\'94 principals. Most notably, the attributes prefixed \'93participant_\'94 contained multiple values per cell, delimited by a combination of [:digit:], :: and/or ||. In order to be computationally efficient, it was decided to first subset `gvd` before cleaning the aforementioned \'93participant_\'94 attributes.  As the `acs2015` dataset contained values from only the 2015 American (US) Census, the first subset involved filtering values of the year 2015 from the `gvd` dataset. \
This was achieved using the `as.logical()` and `year()` functions, creating and applying a boolean vector to `gvd` to create the dataset `gvd2015`. This methodology enabled us to retain the native date format YYYY-MM-DD. The `gvd2015` was then filtered for values which satisfied the condition `state == \'93California\'94`, giving `gvd2015_keep_cali`. A custom function was written and employed to scour through the `participant_age` column of `gvd2015`. This resulted in capturing age counts of incident participants by binning them into approximately 5-years bin intervals. The `participant, _gender, _status, _type` columns were then also all stripped of string prefix values and binned. The resultant `killed_count` and `injured_count` matched perfectly the original `n_killed` and `n_injured` attributes, indicating an extremely precise processing methodology. It was determined that the `incident_url` column of `gvd2015_keep_cali` could be dropped, as the URL prefix in every case matched the unique incident ID.\
The `acs2015` dataset was then filtered for values from the state of California.\
\
Using `data.frame` with piping, `gvd` was checked for dimensions (239677 observations of 29 attributes), column names and data types. The structure of the data frame indicates wide format, where the 'subject information' is indicated by the unique value `incident_id`. This was confirmed by `length(unique(gvd$incident_id))` which gave 239677 unique observations, which is equal to the total number of observations (all observations are unique).\
\
 OriginalValue | Explanation / Justification | UpdatedValue\
------------- | ------------------------------------------------- | -----------\
`InjuredUnharmedArrested` | This value was created as the reporting of an incident is updated | `InjuredArrested`\
`KilledInjured` | This value was created when a person who was initially injured later dies | `Killed`\
`KilledArrested` | This value was created when a person who was mortally wounded, arrested and later dies | `Killed`\
`KilledUnharmed` | This value was created as the reporting of an incident is updated | `Killed`\
`InjuredUnharmed` | This value was created as the reporting of an incident is updated | `Injured`\
`KilledUnharmedArrested` | This value was created as the reporting of an incident is updated | `Killed`\
\
 Feature 		| gvd 					| acs2015\
------------- 	      | ------------------------------------------------- | -----------\
Observations   | 239677 | 3220\
Attributes   | 29 |  37\
Tidy | No | Yes\
Format | Wide | Wide \
Unique Ref   | Yes - IncidentID | Yes - CensusID \
Incorrect Class  | Attribute 1, 5, 8:14, 16, 19 |  Attribute 1\
Contains NA  | Attribute 11, 15, 17, 18, 28, 29 | Attribute 14, 15, 19  \
\
\
\
The data frame `gvd` was \
\
Subsequently the `congress`,`` & `` \
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\pard\pardeftab720\sl340\sa240\partightenfactor0

\f2\fs24 \cf2 \cb1 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs36 \cf0 \kerning1\expnd0\expndtw0 \
\
}